{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d01eb39-d060-475e-a61e-d3a3384ca82b",
   "metadata": {},
   "source": [
    "# Alexandria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "565c2c8c-0a13-4464-86a5-70970942601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "import randomcolor\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import operator as ops\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import zlib\n",
    "import base64\n",
    "import itertools\n",
    "import random\n",
    "from termcolor import colored\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "rcolor = randomcolor.RandomColor()\n",
    "\n",
    "def L(x, y):\n",
    "    return lambda x: y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15c38c3-ca20-4108-ac86-fcae6bbe49bc",
   "metadata": {},
   "source": [
    "## Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "05dd6b8d-bb60-4f71-a59e-23b22f7970fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Page:\n",
    "    def __init__(self, info, unpack=False, lead='', **kwargs):\n",
    "        if ' ' in info:\n",
    "            parts = info.split(' | ')\n",
    "        else:\n",
    "            parts = info, ''\n",
    "        self.url, self.title = parts[0], ''.join(parts[1:])\n",
    "        self.parse = urlparse(self.url)\n",
    "        self.params = parse_qs(self.parse.query)\n",
    "        self.tags = []\n",
    "        self.len = len(self.url)\n",
    "        self.archives = []\n",
    "        \n",
    "        if unpack:\n",
    "#             if 'url' in self.params and self.params['url'][0].startswith(lead):\n",
    "            if self.url.startswith(lead):\n",
    "                nested = Page(self.params['url'][0])\n",
    "                self.url = nested.url\n",
    "                self.params |= nested.params\n",
    "        \n",
    "        exclude = {'http', 'https', 'www', 'com', 'an', 'in', 'the', 'with', 'and', 'org', 'a', 'as', 'en', 'of', 'to', 'at', 'all', 'for', 'we', 'how', 'it', 'do', 'why', 'be', 'have'}\n",
    "        terms = list(itertools.chain.from_iterable(self.replace(attr.lower(), ' ').split() for attr in [self.url, self.title]))\n",
    "        self.keywords = {t for t in terms if len(t) < 50 and not t.isnumeric()} - exclude\n",
    "    \n",
    "    def tag(self, tags, g=None):\n",
    "        if type(tags) is str:\n",
    "            tags = Tag(tags)\n",
    "        if type(tags) is Tag:\n",
    "            tags = [tags]\n",
    "        \n",
    "        self.tags.extend(tags)\n",
    "        for tag in tags:\n",
    "            g.add_edge(self.title, tag.name, weight=1)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def replace(self, s, n):\n",
    "        punctuation = '.,/_-:?()[]'\n",
    "        for p in punctuation:\n",
    "            s = s.replace(p, n)\n",
    "        return s\n",
    "    \n",
    "    def print(self):\n",
    "        print(str(self))\n",
    "        \n",
    "    def __str__(self):\n",
    "        return ' | '.join([self.title, '; '.join(map(str, self.tags)), '; '.join(self.keywords), self.url[:100]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823b487d-a162-4972-8a15-c4466dec93cc",
   "metadata": {},
   "source": [
    "## Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "1ec13c19-9d18-4253-9fbd-605d8043173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tag:\n",
    "    def __init__(self, name=''):\n",
    "        self.name = name\n",
    "#         self.color = rcolor.generate()\n",
    "        colors = [\n",
    "            'grey',\n",
    "            'red',\n",
    "            'green',\n",
    "            'yellow',\n",
    "            'blue',\n",
    "            'magenta',\n",
    "            'cyan',\n",
    "            'white'\n",
    "        ]\n",
    "        self.color = random.choice(colors)\n",
    "        self.created = str(datetime.datetime.now())\n",
    "        \n",
    "    def __str__(self):\n",
    "        return colored(self.name, self.color)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9c23c3-084b-4f89-bb78-6beb38f8a753",
   "metadata": {},
   "source": [
    "## Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "4b64e433-362f-4731-a335-cd63e645565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Collection:\n",
    "    def __init__(self, urls=None, source='', encoding='utf8'):\n",
    "        self.urls = []\n",
    "        self.graph = nx.Graph()\n",
    "        if urls:\n",
    "            self.add(urls)\n",
    "        \n",
    "        if source:\n",
    "            with open(source, 'r', encoding=encoding) as file:\n",
    "                text = file.read()\n",
    "                text = text.encode(encoding)\n",
    "                text = base64.b64decode(text)\n",
    "                text = zlib.decompress(text)\n",
    "                text = text.decode(encoding)\n",
    "#             print(text[:500])\n",
    "    \n",
    "    def load(self, path, limit=50, **kwargs):\n",
    "        data = []\n",
    "        with open(path, 'r', encoding='utf8') as file:\n",
    "            l = 0\n",
    "            for line in file:\n",
    "                data.append(line)\n",
    "                if l > limit:\n",
    "                    break\n",
    "                l += 1\n",
    "        self.add(data, **kwargs)\n",
    "    \n",
    "    def add(self, urls, **kwargs):\n",
    "        if type(urls) is str:\n",
    "            urls = [urls]\n",
    "        if type(urls) is list:\n",
    "            for url in urls:\n",
    "                if type(url) is str:\n",
    "                    new = Page(url, **kwargs)\n",
    "                elif type(url) is Page:\n",
    "                    new = url\n",
    "                self.urls.append(new)\n",
    "                self.graph.add_node(new.title, color='green', label=' ')\n",
    "    \n",
    "    def find(self, attr, value=None):\n",
    "        if not callable(attr):\n",
    "            attr = lambda x: getattr(x, attr) == value\n",
    "        return Collection(list(filter(attr, self.urls)))\n",
    "    \n",
    "    def tag(self, tags):\n",
    "        if type(tags) is str:\n",
    "            tags = Tag(tags)\n",
    "        if type(tags) is Tag:\n",
    "            tags = [tags]\n",
    "        \n",
    "        for u in self.urls:\n",
    "            u.tags.extend(tags)\n",
    "            for tag in tags:\n",
    "#                 print(tag.name, u.title)\n",
    "                self.graph.add_edge(u.title, tag.name, weight=1)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def tag_if_in(self, tags):\n",
    "        if type(tags) is str:\n",
    "            tags = [tags]\n",
    "        result = self\n",
    "#         tags_ = [Tag(t) for t in tags]\n",
    "        tags_ = []\n",
    "        for t in tags:\n",
    "            t_ = Tag(t)\n",
    "            tags_.append(t_)\n",
    "            self.graph.add_node(t_.name, color='purple')\n",
    "        \n",
    "        for t in tags_:\n",
    "#             print(t.name)\n",
    "#             result.find(lambda x: any(t.name.lower().replace(' ', '') in q for q in [x.title, x.url])).tag(t)\n",
    "            for u in result.urls:\n",
    "                if any(t.name.lower().replace(' ', '') in q for q in [u.title, u.url]):\n",
    "                    u.tag(t, self.graph)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def visualize(self, property='len'):\n",
    "        summary = [getattr(u, property) for u in self.urls]\n",
    "        plt.hist(summary, bins=100)\n",
    "        \n",
    "    def network(self, physics=False):\n",
    "        self.vis = Network(width=800, height=800, notebook=True)\n",
    "#         print(self.graph.nodes)\n",
    "        self.vis.from_nx(self.graph)\n",
    "#         self.vis.enable_physics(physics)\n",
    "        self.vis.toggle_physics(physics)\n",
    "#         g.barnes_hut()\n",
    "        output = self.vis.show('./library-network.html')\n",
    "#         return net\n",
    "        return output\n",
    "        \n",
    "        \n",
    "    def download(self, limit=1, rate=1):\n",
    "        for u in self.urls[:limit]:\n",
    "            text = requests.get(u.url).text\n",
    "            u.archives.append(text)\n",
    "            time.sleep(1/rate)\n",
    "            \n",
    "    def save(self, path='./alexandria-library.txt', encoding='utf-8'):\n",
    "        text = json.dumps(self, default=vars)\n",
    "        text = zlib.compress(text.encode(encoding))\n",
    "        text = base64.b64encode(text)\n",
    "        with open(path, 'w') as f:\n",
    "#             f.write(text.decode(encoding, 'ignore'))\n",
    "            f.write(text.decode(encoding))\n",
    "#             f.write(text)\n",
    "    \n",
    "    def print(self, limit=100):\n",
    "        for u in self.urls[:limit]:\n",
    "            print(u)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.urls[i]\n",
    "\n",
    "class Rule:\n",
    "    def __init__(self, z, op, value, action):\n",
    "        if callable(z):\n",
    "            self.when = z\n",
    "        else:\n",
    "            self.when = lambda x: op(getattr(x, z), value)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbb66d0-a952-4312-9e18-4f2d94d85ec0",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "babe8642-a51a-46be-bae0-3634026279b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Collection at 0x11d473f1100>"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Collection(source='./alexandria-library.txt')\n",
    "c.load('./may-28.txt', unpack=True, lead='chrome-extension://fiabciakcmgepblmdkmemdbbkilneeeh/park.html', limit=200)\n",
    "\n",
    "# print(c.urls[100].parse)\n",
    "# c.find(lambda x: len(x.url)>1000)[5]\n",
    "# w = c.find(lambda x: 'Wikipedia' in x.title).tag('Wikipedia')\n",
    "# w[0]\n",
    "# t.created\n",
    "# c.tag(t)[0].tags[0].name\n",
    "# c[100].params\n",
    "# c.find(lambda x: x.len < 600).visualize()\n",
    "\n",
    "c.tag_if_in(['Wikipedia', 'Google', 'Colab', 'Stack Overflow', 'GitHub', 'Twitter', 'YouTube', 'Stack Exchange', 'Physics', 'The New York Times', 'NumPy'])\n",
    "# w.tag('Page')\n",
    "# [([t.name for t in g.tags], g.url[-5:]) for g in w[:50]]\n",
    "\n",
    "# r = Rule('url', ops.eq, 'wikipedia.org', None)\n",
    "# w.download()\n",
    "# w.print()\n",
    "# w.save()\n",
    "# w.graph.edges\n",
    "\n",
    "# c.network(physics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "4573150b-5653-4702-85f6-011d1f1e2f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(width=800, height=800, notebook=True)\n",
    "net.from_nx(w.graph)\n",
    "# net.show(\"./library-network.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "a529de6b-c1c6-4ce6-80fa-2235dfdbd711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# print(w.graph.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "ba0a0ebd-1168-45a3-b92e-517c48fdd8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x1b[31mtest\\x1b[0m'"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colored('test', 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "7360232c-68a8-4454-bf18-4d70f3e48095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w[1].params['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "b0d06c93-03b1-4ca3-bc64-824f9c6b4e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE '"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = requests.get('https://stackoverflow.com/questions/2018026/what-are-the-differences-between-the-urllib-urllib2-urllib3-and-requests-modul')\n",
    "output.text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "fcbb70ac-9755-4ccb-9bcf-b52d41067ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "0f2995ba-ca10-48e5-a399-75ed1c0b5f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
